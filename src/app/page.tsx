
'use client'

import { useState, useEffect, useRef, useCallback } from 'react'
import { selectPandaReply, type PandaReply } from '@/data/replies'
import {
  speakLikePandaWithAnalysis,
  speakLikePanda,
  initializeAudioContext,
  createVariedSpeechParams,
  type SpeechAnalysisResult
} from '@/lib/pandaSpeech'
import {
  loadPandaMemory,
  savePandaMemory,
  recordConversation,
  getIntimacyAdjustedParams,
  getIntimacyMessage,
  getIntimacyLevelName,
  type PandaMemory
} from '@/lib/pandaLearning'
import Bubble from '@/components/Bubble'
import QuickChips from '@/components/QuickChips'
import IntimacyGauge from '@/components/IntimacyGauge'
import MilestoneNotification from '@/components/MilestoneNotification'
import ShareCardGenerator from '@/components/ShareCardGenerator'
import VoiceInput from '@/components/VoiceInput'

// æ–°æ©Ÿèƒ½ã®import
import dynamic from 'next/dynamic'
import { createAnalyser } from '@/lib/audio/analyserBridge'
import { FeatureAggregator, extractFeatures } from '@/lib/audio/featureExtractor'
import { IntentClassifier } from '@/lib/audio/intentClassifier'
import type { AnalyserBridge, IntentResult, GrainTimeline } from '@/types/audio'

// CSRå°‚ç”¨ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
const SpectrumPanel = dynamic(() => import('@/components/SpectrumPanel'), { ssr: false })
const TranslationCaption = dynamic(() => import('@/components/TranslationCaption'), { ssr: false })

export default function Home() {
  console.log('ğŸ—ï¸ Home component rendering...')

  const [userInput, setUserInput] = useState('')
  const [currentReply, setCurrentReply] = useState<PandaReply | null>(null)
  const [isSpeaking, setIsSpeaking] = useState(false)
  const [isThinking, setIsThinking] = useState(false)
  const [autoSpeakEnabled, setAutoSpeakEnabled] = useState(false)
  const [audioInitialized, setAudioInitialized] = useState(false)

  // å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ é–¢é€£ï¼ˆSSRå¯¾å¿œã®ãŸã‚åˆæœŸå€¤ã‚’ä½¿ç”¨ï¼‰
  const [pandaMemory, setPandaMemory] = useState<PandaMemory>(() => {
    // SSRæ™‚ã¯å¸¸ã«åˆæœŸå€¤ã‚’è¿”ã™
    if (typeof window === 'undefined') {
      return {
        totalConversations: 0,
        uniqueDays: 0,
        firstMeeting: null,
        lastSeen: null,
        favoriteQuestions: [],
        conversationHistory: [],
        totalSessionTime: 0,
        intimacyLevel: 0,
        longestSession: 0,
        consecutiveDays: 0,
        preferredResponseStyle: 'mixed' as const,
        specialUnlocks: []
      }
    }
    return loadPandaMemory()
  })
  const [intimacyAnimating, setIntimacyAnimating] = useState(false)
  const [sessionStartTime, setSessionStartTime] = useState<Date | null>(null)
  const [newUnlocks, setNewUnlocks] = useState<string[]>([])
  const [showMilestone, setShowMilestone] = useState(false)
  const [showShareCard, setShowShareCard] = useState(false)
  const [isClientMounted, setIsClientMounted] = useState(false)

  // æ–°æ©Ÿèƒ½ã®state
  const [analyserBridge, setAnalyserBridge] = useState<AnalyserBridge | null>(null)
  const [isAnalysisEnabled, setIsAnalysisEnabled] = useState(true)
  const [currentIntentResult, setCurrentIntentResult] = useState<IntentResult | null>(null)
  const [currentPandaSound, setCurrentPandaSound] = useState('')
  const [currentTranslation, setCurrentTranslation] = useState('')
  const [currentGrainTimeline, setCurrentGrainTimeline] = useState<GrainTimeline[]>([])
  const [isAnalyzing, setIsAnalyzing] = useState(false)

  const autoSpeakTimer = useRef<NodeJS.Timeout | null>(null)
  const audioContextRef = useRef<AudioContext | null>(null)

  // æ–°æ©Ÿèƒ½ã®ref
  const featureAggregatorRef = useRef<FeatureAggregator>(new FeatureAggregator())
  const intentClassifierRef = useRef<IntentClassifier>(new IntentClassifier())
  const analysisIntervalRef = useRef<NodeJS.Timeout | null>(null)

  // ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚µã‚¤ãƒ‰ã§ã®åˆæœŸåŒ–
  useEffect(() => {
    console.log('ğŸ  Component mounting/updating...')

    // ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒã‚¦ãƒ³ãƒˆæ¤œçŸ¥
    setIsClientMounted(true)

    // ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹æ™‚åˆ»ã®åˆæœŸåŒ–
    if (!sessionStartTime) {
      setSessionStartTime(new Date())
    }

    // localStorageã‹ã‚‰pandaMemoryã‚’èª­ã¿è¾¼ã¿ï¼ˆåˆå›ã®ã¿ï¼‰
    const actualMemory = loadPandaMemory()
    setPandaMemory(actualMemory)

    console.log('ğŸ“Š Component state:', {
      isAnalysisEnabled,
      hasAnalyserBridge: !!analyserBridge,
      isClientMounted
    })
  }, [sessionStartTime]) // sessionStartTimeã‚’ä¾å­˜é…åˆ—ã«è¿½åŠ 

  // éŸ³å£°ç™ºè©±å‡¦ç†ï¼ˆå­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ çµ±åˆç‰ˆï¼‰
  const performSpeech = useCallback(async (input: string, isUserInput: boolean = true) => {
    console.log('ğŸ¤ performSpeech called:', { input, isUserInput, isSpeaking })

    if (isSpeaking) {
      console.log('â¸ï¸ Already speaking, returning early')
      return
    }

    console.log('ğŸ”„ Starting speech performance...')

    try {
      // è€ƒãˆä¸­çŠ¶æ…‹ã‚’è¡¨ç¤ºï¼ˆ250msï¼‰
      setIsThinking(true)
      await new Promise(resolve => setTimeout(resolve, 250))
      setIsThinking(false)

      setIsSpeaking(true)

      // è¿”ç­”ã‚’é¸æŠ
      const reply = selectPandaReply(input)

      // AudioContextã®åˆæœŸåŒ–
      if (!audioContextRef.current) {
        audioContextRef.current = await initializeAudioContext()
        setAudioInitialized(true)
      }

      // AnalyserBridgeã®ä½œæˆï¼ˆæ¯å›ãƒã‚§ãƒƒã‚¯ï¼‰
      let currentAnalyserBridge = analyserBridge
      if (isAnalysisEnabled && audioContextRef.current && !currentAnalyserBridge) {
        try {
          console.log('ğŸ”¬ Creating analyser bridge...')
          const analyser = createAnalyser(audioContextRef.current)
          setAnalyserBridge(analyser)
          currentAnalyserBridge = analyser // ä»Šå›ã®å‡¦ç†ã§ä½¿ç”¨
          console.log('âœ… Analyser bridge created successfully')
        } catch (error) {
          console.error('âŒ Failed to create analyser:', error)
        }
      }

      // æ„å›³ã«å¿œã˜ãŸãƒ™ãƒ¼ã‚¹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
      let intent: 'greeting' | 'hungry' | 'playful' | 'random' = 'random'
      if (reply.id === 1) intent = 'hungry'
      else if (reply.id === 2) intent = 'playful'
      else if (reply.id === 3) intent = 'greeting'

      const baseSpeechParams = createVariedSpeechParams(intent)

      // ğŸ§  è¦ªå¯†åº¦ã«åŸºã¥ã„ã¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª¿æ•´
      const intimacyAdjustedParams = getIntimacyAdjustedParams(
        baseSpeechParams,
        pandaMemory.intimacyLevel,
        pandaMemory.preferredResponseStyle
      )

      // è§£ææ©Ÿèƒ½ä»˜ãéŸ³å£°å†ç”Ÿ
      let speechResult: SpeechAnalysisResult
      if (isAnalysisEnabled && currentAnalyserBridge) {
        console.log('ğŸµ Starting analysis-enabled speech synthesis')

        // ç‰¹å¾´é‡ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°é–‹å§‹
        setIsAnalyzing(true)
        featureAggregatorRef.current.clear()

        // å®šæœŸçš„ã«ç‰¹å¾´é‡ã‚’æŠ½å‡º
        analysisIntervalRef.current = setInterval(() => {
          if (currentAnalyserBridge) {
            const frequencyData = currentAnalyserBridge.getFrequencyFrame()
            const timeData = currentAnalyserBridge.getTimeFrame()
            const features = extractFeatures(frequencyData, timeData)
            featureAggregatorRef.current.addSample(features)
          }
        }, 50) // 20Hz ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°

        speechResult = await speakLikePandaWithAnalysis(
          audioContextRef.current,
          reply.src,
          intimacyAdjustedParams,
          currentAnalyserBridge
        )
      } else {
        console.log('âš ï¸ Using traditional speech synthesis:', {
          isAnalysisEnabled,
          hasAnalyserBridge: !!analyserBridge,
          hasCurrentAnalyserBridge: !!currentAnalyserBridge
        })

        // å¾“æ¥ã®æ–¹å¼
        const duration = await speakLikePanda(audioContextRef.current, reply.src, intimacyAdjustedParams)
        speechResult = {
          actualDuration: duration,
          grainTimeline: []
        }
      }

      // ç¿»è¨³è¡¨ç¤º
      setCurrentReply(reply)
      if (isUserInput) {
        setUserInput('')
      }

      // ğŸ§  ä¼šè©±ã‚’è¨˜éŒ²ã—ã¦å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°
      if (isUserInput) {
        // sessionStartTime ãŒ null ã®å ´åˆã¯ç¾åœ¨ã®æ™‚åˆ»ã§åˆæœŸåŒ–
        const startTime = sessionStartTime || new Date()
        const sessionDuration = Math.floor((Date.now() - startTime.getTime()) / 1000)
        const previousIntimacy = pandaMemory.intimacyLevel
        const previousUnlocks = [...pandaMemory.specialUnlocks]

        const updatedMemory = recordConversation(
          pandaMemory,
          input,
          { id: reply.id, translation: reply.translation },
          Math.max(sessionDuration, 5) // æœ€ä½5ç§’ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³æ™‚é–“
        )

        setPandaMemory(updatedMemory)
        savePandaMemory(updatedMemory)

        // è¦ªå¯†åº¦ãŒä¸ŠãŒã£ãŸã‚‰ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³
        if (updatedMemory.intimacyLevel > previousIntimacy) {
          setIntimacyAnimating(true)
          setTimeout(() => setIntimacyAnimating(false), 2000)
        }

        // æ–°ã—ã„è§£æ”¾ãŒã‚ã£ãŸå ´åˆã®é€šçŸ¥
        const newUnlocksList = updatedMemory.specialUnlocks.filter(
          unlock => !previousUnlocks.includes(unlock)
        )

        if (newUnlocksList.length > 0) {
          setNewUnlocks(newUnlocksList)
          setShowMilestone(true)
        }

        // ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹æ™‚åˆ»ã‚’ãƒªã‚»ãƒƒãƒˆ
        setSessionStartTime(new Date())
      }

      // è§£æçµæœã®å‡¦ç†
      if (isAnalysisEnabled && analysisIntervalRef.current) {
        // ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°åœæ­¢
        clearInterval(analysisIntervalRef.current)
        analysisIntervalRef.current = null

        // ç‰¹å¾´é‡é›†è¨ˆã¨åˆ†é¡
        const aggregate = featureAggregatorRef.current.getAggregate()
        console.log('ğŸ“Š Feature aggregate:', aggregate)

        if (aggregate.sampleCount > 0) {
          const intentResult = intentClassifierRef.current.classify(aggregate)
          const pandaSound = intentClassifierRef.current.getRandomPandaSound(intentResult.intent)
          const translation = intentClassifierRef.current.getRandomTranslation(intentResult.intent)

          console.log('ğŸ¯ Classification result:', { intent: intentResult.intent, confidence: intentResult.confidence })
          console.log('ğŸ¼ Panda sound:', pandaSound)
          console.log('ğŸ—£ï¸ Translation:', translation)

          setCurrentIntentResult(intentResult)
          setCurrentPandaSound(pandaSound)
          setCurrentTranslation(translation)
          setCurrentGrainTimeline(speechResult.grainTimeline)
        } else {
          console.warn('âš ï¸ No samples collected for analysis')
        }

        // ä¸€å®šæ™‚é–“å¾Œã«è§£æçŠ¶æ…‹ã‚’çµ‚äº†
        setTimeout(() => {
          setIsAnalyzing(false)
        }, speechResult.actualDuration * 1000 + 500)
      }

      // å®Ÿéš›ã®éŸ³å£°æ™‚é–“ã«åŸºã¥ã„ã¦ç™ºè©±çµ‚äº†ã‚’ç®¡ç†ï¼ˆä½™è£•ã‚’æŒãŸã›ã¦ï¼‰
      const finalDuration = speechResult.actualDuration + 0.5 // 0.5ç§’ã®ä½™è£•ã‚’è¿½åŠ 

      setTimeout(() => {
        setIsSpeaking(false)
      }, finalDuration * 1000)

    } catch (error) {
      console.error('Speech synthesis failed:', error)
      setIsSpeaking(false)
    }
  }, [isSpeaking, pandaMemory, sessionStartTime])

  // è‡ªå‹•ç™ºè©±å‡¦ç†
  const handleAutoSpeak = useCallback(async () => {
    console.log('ğŸ¤– Auto speak triggered')
    if (isSpeaking) {
      console.log('âŒ Auto speak blocked, already speaking')
      return
    }

    const randomInput = ['ãŠã¾ã‹ã›ã§é³´ã', 'ã“ã‚“ã«ã¡ã¯', 'ã‚ãã¼'][Math.floor(Math.random() * 3)]
    console.log('âœ… Calling performSpeech from AutoSpeak:', randomInput)
    await performSpeech(randomInput, false)
  }, [isSpeaking, performSpeech])

  // ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
  useEffect(() => {
    return () => {
      if (autoSpeakTimer.current) {
        clearTimeout(autoSpeakTimer.current)
      }
      if (audioContextRef.current) {
        audioContextRef.current.close()
      }
    }
  }, [])

  // è‡ªå‹•ç™ºè©±åˆ¶å¾¡
  useEffect(() => {
    if (autoSpeakEnabled && audioInitialized && !isSpeaking) {
      const scheduleNext = () => {
        const delay = Math.random() * 10000 + 10000 // 10-20ç§’
        autoSpeakTimer.current = setTimeout(async () => {
          if (autoSpeakEnabled && !isSpeaking) {
            await handleAutoSpeak()
          }
          if (autoSpeakEnabled) scheduleNext()
        }, delay)
      }
      scheduleNext()
    } else if (autoSpeakTimer.current) {
      clearTimeout(autoSpeakTimer.current)
      autoSpeakTimer.current = null
    }

    return () => {
      if (autoSpeakTimer.current) {
        clearTimeout(autoSpeakTimer.current)
        autoSpeakTimer.current = null
      }
    }
  }, [autoSpeakEnabled, audioInitialized, isSpeaking, handleAutoSpeak])

  const handleSubmit = async (e: React.FormEvent) => {    
    e.preventDefault()
    console.log('ğŸš€ Form submitted:', { userInput: userInput.trim(), isSpeaking })
    if (userInput.trim() && !isSpeaking) {
      console.log('âœ… Calling performSpeech with:', userInput.trim())
      await performSpeech(userInput.trim())
    } else {
      console.log('âŒ Submit blocked:', { hasInput: !!userInput.trim(), isSpeaking })
    }
  }

  const handleQuickQuestion = async (question: string) => {
    console.log('ğŸ¯ Quick question clicked:', question)
    if (!isSpeaking) {
      console.log('âœ… Calling performSpeech from QuickChips')
      await performSpeech(question)
    } else {
      console.log('âŒ Quick question blocked, already speaking')
    }
  }

  const toggleAutoSpeak = () => {
    setAutoSpeakEnabled(!autoSpeakEnabled)
  }

  const toggleAnalysis = () => {
    setIsAnalysisEnabled(!isAnalysisEnabled)

    // è§£æç„¡åŠ¹åŒ–æ™‚ã¯ç¾åœ¨ã®çŠ¶æ…‹ã‚’ã‚¯ãƒªã‚¢
    if (isAnalysisEnabled) {
      setCurrentIntentResult(null)
      setCurrentPandaSound('')
      setCurrentTranslation('')
      setCurrentGrainTimeline([])
      setIsAnalyzing(false)

      if (analysisIntervalRef.current) {
        clearInterval(analysisIntervalRef.current)
        analysisIntervalRef.current = null
      }
    }
  }

  const handleShareCard = () => {
    setShowShareCard(true)
  }

  const handleVoiceInput = async (voiceText: string) => {
    console.log('ğŸ¤ Voice input received:', voiceText)
    if (!isSpeaking && !isThinking) {
      console.log('âœ… Calling performSpeech from VoiceInput')
      await performSpeech(voiceText)
    } else {
      console.log('âŒ Voice input blocked:', { isSpeaking, isThinking })
    }
  }

  // ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³IDã‹ã‚‰ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—ã™ã‚‹é–¢æ•°
  const getMilestoneTitle = (id: string): string => {
    const milestoneData: Record<string, string> = {
      chatty_friend: 'ãŠã—ã‚ƒã¹ã‚Šå¥½ã',
      close_buddy: 'è¦ªå¯†ãªå‹é”',
      regular_visitor: 'å¸¸é€£ã•ã‚“',
      weekly_friend: '1é€±é–“ã®å‹',
      early_bird: 'æœã®å‹é”',
      night_owl: 'å¤œãµã‹ã—å‹é”',
      long_talker: 'ãŠã—ã‚ƒã¹ã‚Šä¸Šæ‰‹'
    }
    return milestoneData[id] || id
  }

  const isDisabled = isSpeaking || isThinking

  return (
    <div className="min-h-screen bg-gradient-to-b from-amber-100 to-amber-200">
      <main className="flex flex-col items-center justify-center min-h-screen p-4">
        <div className="w-full max-w-md space-y-6">
          {/* ãƒ˜ãƒƒãƒ€ãƒ¼ */}
          <div className="text-center">
            <h1 className="text-3xl font-bold text-orange-900 mb-2">
              ğŸ¼ ã—ã‚ƒã¹ã‚Œã£ã•ãƒ¼ï¼ ğŸ¼
            </h1>
            <p className="text-sm text-gray-600 mb-1">
              ãƒ¬ãƒƒã‚µãƒ¼ãƒ‘ãƒ³ãƒ€ã¨&quot;ãŠã—ã‚ƒã¹ã‚Š&quot;ï¼ˆæ¨¡æ“¬ç¿»è¨³ï¼‰
            </p>
            <p className="text-xs text-orange-600 font-medium">
              ğŸ”Š éŸ³é‡ã«ã”æ³¨æ„ãã ã•ã„
            </p>
          </div>

          {/* å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ  */}
          <form onSubmit={handleSubmit} className="space-y-4">
            <div className="relative">
              <input
                type="text"
                value={userInput}
                onChange={(e) => setUserInput(e.target.value)}
                placeholder="ãƒ¬ãƒƒã‚µãƒ¼ãƒ‘ãƒ³ãƒ€ã«è©±ã—ã‹ã‘ã¦ã­..."
                className="w-full px-4 py-3 rounded-lg border border-orange-200 focus:outline-none focus:ring-2 focus:ring-orange-300 focus:border-transparent disabled:bg-gray-50"
                disabled={isDisabled}
                aria-label="ãƒ¬ãƒƒã‚µãƒ¼ãƒ‘ãƒ³ãƒ€ã¸ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å…¥åŠ›"
              />
            </div>
            <button
              type="submit"
              disabled={!userInput.trim() || isDisabled}
              className="w-full bg-orange-500 text-white px-6 py-3 rounded-lg shadow-md hover:bg-orange-600 transition disabled:bg-gray-300 disabled:cursor-not-allowed focus:ring-2 focus:ring-orange-300 focus:outline-none"
              aria-label="ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡ã—ã¦ãƒ¬ãƒƒã‚µãƒ¼ãƒ‘ãƒ³ãƒ€ã«è©±ã—ã‹ã‘ã‚‹"
            >
              {isThinking ? 'è€ƒãˆä¸­...' : isSpeaking ? 'é³´ã„ã¦ã„ã¾ã™...' : 'è©±ã—ã‹ã‘ã‚‹'}
            </button>
          </form>

          {/* éŸ³å£°å…¥åŠ› */}
          <VoiceInput
            onVoiceInput={handleVoiceInput}
            disabled={isDisabled}
            isProcessing={isSpeaking || isThinking}
          />

          {/* ãƒ—ãƒªã‚»ãƒƒãƒˆè³ªå• */}
          <QuickChips
            onQuickQuestion={handleQuickQuestion}
            disabled={isDisabled}
          />

          {/* AIè§£ææ©Ÿèƒ½ã®åˆ‡ã‚Šæ›¿ãˆ */}
          <div className="bg-white rounded-lg p-4 border border-orange-200 shadow-sm">
            <label className="flex items-center space-x-3 cursor-pointer">
              <input
                type="checkbox"
                checked={isAnalysisEnabled}
                onChange={toggleAnalysis}
                className="w-4 h-4 text-blue-500 border-gray-300 rounded focus:ring-blue-300"
              />
              <div>
                <span className="text-sm font-medium text-gray-700">
                  ğŸ”¬ AIéŸ³å£°è§£æï¼†ç¿»è¨³
                </span>
                <p className="text-xs text-gray-500 mt-1">
                  ãƒ‘ãƒ³ãƒ€ã®é³´ãå£°ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è§£æã—ã¦æ„å›³ã‚’æ¨æ¸¬ã—ã¾ã™
                </p>
              </div>
            </label>
          </div>

          {/* ã‚¹ãƒšã‚¯ãƒˆãƒ©ãƒ è§£æãƒ‘ãƒãƒ« */}
          {isAnalysisEnabled && (
            <div className="space-y-4">
              <SpectrumPanel
                analyserBridge={analyserBridge}
                isActive={isAnalyzing}
                className="h-32"
              />

              <TranslationCaption
                intentResult={currentIntentResult}
                pandaSound={currentPandaSound}
                translation={currentTranslation}
                grainTimeline={currentGrainTimeline}
                isActive={isAnalyzing}
                className="min-h-[160px]"
              />
            </div>
          )}

          {/* ğŸ§  è¦ªå¯†åº¦ã‚²ãƒ¼ã‚¸ */}
          <IntimacyGauge
            intimacyLevel={pandaMemory.intimacyLevel}
            totalConversations={pandaMemory.totalConversations}
            relationshipName={getIntimacyLevelName(pandaMemory.intimacyLevel)}
            message={getIntimacyMessage(pandaMemory.intimacyLevel)}
            isAnimating={intimacyAnimating}
            onShareCard={handleShareCard}
          />

          {/* è‡ªå‹•ç™ºè©±ãƒˆã‚°ãƒ« */}
          <div className="bg-white rounded-lg p-4 border border-orange-200 shadow-sm">
            <label className="flex items-center space-x-3 cursor-pointer">
              <input
                type="checkbox"
                checked={autoSpeakEnabled}
                onChange={toggleAutoSpeak}
                className="w-4 h-4 text-orange-500 border-gray-300 rounded focus:ring-orange-300"
                aria-describedby="auto-speak-description"
              />
              <div>
                <span className="text-sm font-medium text-gray-700">
                  ğŸ§ª å®Ÿé¨“ï¼šãƒ‘ãƒ³ãƒ€ãŒ&quot;è‡ªç”±ã«ã—ã‚ƒã¹ã‚‹&quot;
                </span>
                <p id="auto-speak-description" className="text-xs text-gray-500 mt-1" suppressHydrationWarning>
                  10ã€œ20ç§’ã”ã¨ã«è‡ªå‹•ã§é³´ãã¾ã™ï¼ˆè¦ªå¯†åº¦:{pandaMemory.intimacyLevel}%ï¼‰
                </p>
              </div>
            </label>
          </div>

          {/* è¿”ç­”å¹ãå‡ºã— */}
          <Bubble
            translation={currentReply?.translation || ''}
            isVisible={!!currentReply}
          />

          {/* å­¦ç¿’çŠ¶æ³è¡¨ç¤ºï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰ - CSRå°‚ç”¨ */}
          {isClientMounted && pandaMemory.totalConversations > 0 && (
            <div className="bg-gray-50 rounded-lg p-3 border border-gray-200">
              <div className="text-xs text-gray-600 space-y-1">
                <div>ğŸ§  å­¦ç¿’çŠ¶æ³: {pandaMemory.preferredResponseStyle}ã‚¹ã‚¿ã‚¤ãƒ«</div>
                <div>ğŸ“ˆ ç·ä¼šè©±: {pandaMemory.totalConversations}å›</div>
                {pandaMemory.favoriteQuestions.length > 0 && (
                  <div>â¤ï¸ ã‚ˆãèãè³ªå•: {pandaMemory.favoriteQuestions[0].question}</div>
                )}
                {pandaMemory.specialUnlocks.length > 0 && (
                  <div>ğŸ† è§£æ”¾æ¸ˆã¿: {pandaMemory.specialUnlocks.map(id => getMilestoneTitle(id)).join(', ')}</div>
                )}
              </div>
            </div>
          )}
        </div>
      </main>

      {/* ãƒ•ãƒƒã‚¿ãƒ¼ */}
      <footer className="bg-orange-50 border-t border-orange-200 p-4 text-center text-xs text-gray-600">
        <p className="mb-1">
          â€» ã“ã®ç¿»è¨³ã¯æ“¬ä¼¼çš„ãªæ¼”å‡ºã§ã™ã€‚å®Ÿéš›ã®é³´ãå£°ã®æ„å‘³ã‚’ä¿è¨¼ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚
        </p>
        <p>
          åœ’å†…é™å®šã®&quot;ç‰¹åˆ¥ãƒœã‚¤ã‚¹&quot;ã‚‚æº–å‚™ä¸­ï¼è¥¿å±±å‹•ç‰©åœ’ã§ä¼šã„ã«æ¥ã¦ã­ğŸ¾
        </p>
      </footer>

      {/* ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³é€šçŸ¥ */}
      {showMilestone && (
        <MilestoneNotification
          newUnlocks={newUnlocks}
          onClose={() => {
            setShowMilestone(false)
            setNewUnlocks([])
          }}
        />
      )}

      {/* ã‚·ã‚§ã‚¢ã‚«ãƒ¼ãƒ‰ç”Ÿæˆ */}
      {showShareCard && (
        <ShareCardGenerator
          cardData={{
            intimacyLevel: pandaMemory.intimacyLevel,
            intimacyLevelName: getIntimacyLevelName(pandaMemory.intimacyLevel),
            totalConversations: pandaMemory.totalConversations,
            uniqueDays: pandaMemory.uniqueDays,
            consecutiveDays: pandaMemory.consecutiveDays,
            specialUnlocks: pandaMemory.specialUnlocks,
            relationshipMessage: getIntimacyMessage(pandaMemory.intimacyLevel),
            timestamp: new Date()
          }}
          audioContext={audioContextRef.current}
          onClose={() => setShowShareCard(false)}
        />
      )}
    </div>
  )
}
