'use client'

import { useState, useEffect, useRef, useCallback } from 'react'
import MilestoneNotification from '@/components/MilestoneNotification'
import ShareCardGenerator from '@/components/ShareCardGenerator'
import { useAudioAnalysis } from '@/hooks/useAudioAnalysis'
import { usePandaLearning } from '@/hooks/usePandaLearning'
import { useSpeechSynthesis } from '@/hooks/useSpeechSynthesis'
import { useChatHistory } from '@/hooks/useChatHistory'
import ChatHistory from '@/components/ChatHistory'
import FixedInputArea from '@/components/FixedInputArea'
import StatusPanel from '@/components/StatusPanel'

export default function Home() {
  const [userInput, setUserInput] = useState('')
  const [isClientMounted, setIsClientMounted] = useState(false)
  // éŸ³å£°è§£ææ©Ÿèƒ½
  const [isAnalysisEnabled, setIsAnalysisEnabled] = useState(true)
  // Custom Hooks
  const chatHistory = useChatHistory()
  const speechSynthesis = useSpeechSynthesis({
    enabled: true
  })
  const audioAnalysis = useAudioAnalysis({
    audioContext: speechSynthesis.audioContext,
    enabled: isAnalysisEnabled
  })
  const pandaLearning = usePandaLearning({
    enabled: true
  })
  const autoSpeakTimer = useRef<NodeJS.Timeout | null>(null)

  // ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚µã‚¤ãƒ‰ã§ã®åˆæœŸåŒ–
  useEffect(() => {
    setIsClientMounted(true)
    pandaLearning.initializeMemory()
    speechSynthesis.initializeAudio()
  }, [pandaLearning.sessionStartTime])


  // éŸ³å£°ç™ºè©±å‡¦ç†
  const performSpeech = useCallback(async (input: string, isUserInput: boolean = true) => {
    if (speechSynthesis.isSpeaking) {
      return
    }

    try {
      if (isUserInput) {
        chatHistory.addUserMessage(input)
      }

      speechSynthesis.setIsThinking(true)
      await new Promise(resolve => setTimeout(resolve, 250))
      speechSynthesis.setIsThinking(false)
      speechSynthesis.setIsSpeaking(true)

      // è§£æãŒæœ‰åŠ¹ãªå ´åˆã€analyserBridgeã‚’ç¢ºä¿
      let currentAnalyserBridge = audioAnalysis.analyserBridge
      if (isAnalysisEnabled) {
        // AudioContextã‚’ç¢ºä¿ï¼ˆåˆå›ã®ã¿åˆæœŸåŒ–ï¼‰
        const audioCtx = await speechSynthesis.initializeAudio()

        if (audioCtx && !currentAnalyserBridge) {
          currentAnalyserBridge = await audioAnalysis.initializeAnalyser(audioCtx)
        }

        // analyserBridgeãŒç¢ºä¿ã§ããŸå ´åˆã®ã¿è§£æé–‹å§‹
        if (currentAnalyserBridge) {
          audioAnalysis.startAnalysis(currentAnalyserBridge)
        }
      }

      const reply = speechSynthesis.getReplyForInput(input)
      const baseSpeechParams = speechSynthesis.createSpeechParams(reply.id)
      const adjustedParams = pandaLearning.getAdjustedParams(baseSpeechParams)

      const result = await speechSynthesis.performSpeech({
        input,
        isUserInput,
        adjustedParams,
        analyserBridge: currentAnalyserBridge,
        isAnalysisEnabled
      })

      if (!result) {
        throw new Error('Speech synthesis failed')
      }

      const { reply: actualReply, speechResult } = result

      speechSynthesis.setCurrentReply(actualReply)
      if (isUserInput) {
        setUserInput('')
      }

      if (isUserInput) {
        const startTime = pandaLearning.sessionStartTime || new Date()
        const sessionDuration = Math.floor((Date.now() - startTime.getTime()) / 1000)

        const { intimacyIncreased, newUnlocks: newUnlocksList } = pandaLearning.recordUserConversation({
          userInput: input,
          pandaReply: { id: actualReply.id, translation: actualReply.translation },
          sessionDuration: Math.max(sessionDuration, 5)
        })

        if (intimacyIncreased) {
          pandaLearning.setIntimacyAnimating(true)
          setTimeout(() => pandaLearning.setIntimacyAnimating(false), 2000)
        }

        if (newUnlocksList.length > 0) {
          pandaLearning.setNewUnlocks(newUnlocksList)
          pandaLearning.setShowMilestone(true)
        }
        pandaLearning.resetSessionStartTime()
      }

      const finalDuration = speechResult.actualDuration + 0.5

      // éŸ³å£°å†ç”Ÿå®Œäº†å¾Œã®å‡¦ç†
      setTimeout(() => {
        speechSynthesis.setIsSpeaking(false)

        // è§£æãŒæœ‰åŠ¹ãªå ´åˆã€è§£æã‚’åœæ­¢ã—ã¦çµæœã‚’å‡¦ç†
        if (isAnalysisEnabled) {
          const analysisResult = audioAnalysis.stopAnalysisAndProcess(speechResult.grainTimeline)
          audioAnalysis.setIsAnalyzing(false)

          // è§£æçµæœã‚’ä¼šè©±å±¥æ­´ã«ä¿å­˜
          if (isUserInput && analysisResult) {
            const analysisData = {
              intentResult: analysisResult.intentResult,
              pandaSound: analysisResult.pandaSound,
              translation: analysisResult.translation,
              grainTimeline: analysisResult.grainTimeline
            }
            chatHistory.addPandaMessage(actualReply, analysisData)
          } else if (isUserInput) {
            chatHistory.addPandaMessage(actualReply, undefined)
          }
        } else {
          // è§£æç„¡åŠ¹ã®å ´åˆã¯é€šå¸¸é€šã‚Šä¿å­˜
          if (isUserInput) {
            chatHistory.addPandaMessage(actualReply, undefined)
          }
        }
      }, finalDuration * 1000)

    } catch (error) {
      console.error('Speech synthesis failed:', error)
      speechSynthesis.setIsSpeaking(false)
    }
  }, [speechSynthesis, pandaLearning, isAnalysisEnabled, audioAnalysis, chatHistory])

  // ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
  useEffect(() => {
    return () => {
      if (autoSpeakTimer.current) {
        clearTimeout(autoSpeakTimer.current)
      }
      if (speechSynthesis.audioContext) {
        speechSynthesis.audioContext.close()
      }
    }
  }, [])

  const handleSubmit = async (e: React.FormEvent) => {
    e.preventDefault()
    if (userInput.trim() && !speechSynthesis.isSpeaking) {
      await performSpeech(userInput.trim())
    }
  }

  const handleQuickQuestion = async (question: string) => {
    if (!speechSynthesis.isSpeaking) {
      await performSpeech(question)
    }
  }

  const toggleAnalysis = () => {
    setIsAnalysisEnabled(!isAnalysisEnabled)
  }

  const handleShareCard = () => {
    pandaLearning.setShowShareCard(true)
  }

  const handleVoiceInput = async (voiceText: string) => {
    if (!speechSynthesis.isSpeaking && !speechSynthesis.isThinking) {
      await performSpeech(voiceText)
    }
  }

  // ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³IDã‹ã‚‰ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—ã™ã‚‹é–¢æ•°
  const getMilestoneTitle = (id: string): string => {
    const milestoneData: Record<string, string> = {
      chatty_friend: 'ãŠã—ã‚ƒã¹ã‚Šå¥½ã',
      close_buddy: 'è¦ªå¯†ãªå‹é”',
      regular_visitor: 'å¸¸é€£ã•ã‚“',
      weekly_friend: '1é€±é–“ã®å‹',
      early_bird: 'æœã®å‹é”',
      night_owl: 'å¤œãµã‹ã—å‹é”',
      long_talker: 'ãŠã—ã‚ƒã¹ã‚Šä¸Šæ‰‹'
    }
    return milestoneData[id] || id
  }

  const isDisabled = speechSynthesis.isSpeaking || speechSynthesis.isThinking

  return (
    <div className="min-h-screen bg-gradient-to-br from-orange-50 via-amber-50 to-yellow-50 flex flex-col">
      <div className="bg-white/80 backdrop-blur-sm border-b border-white/30 p-4 flex-shrink-0">
        <div className="max-w-lg mx-auto text-center">
          <div className="mb-2">
            <span className="text-4xl">ğŸ¼</span>
          </div>
          <h1 className="text-2xl font-bold bg-gradient-to-r from-orange-600 to-red-500 bg-clip-text text-transparent mb-2">
            ã—ã‚ƒã¹ã‚Œã£ã•ãƒ¼ï¼
          </h1>
          <p className="text-gray-600 text-sm font-medium">
            ãƒ¬ãƒƒã‚µãƒ¼ãƒ‘ãƒ³ãƒ€ã¨ã®&quot;ãŠã—ã‚ƒã¹ã‚Š&quot;ä½“é¨“
          </p>
        </div>
      </div>

      <div className="flex-1 flex flex-col overflow-hidden">
        <ChatHistory
          messages={chatHistory.messages}
          isAnalyzing={audioAnalysis.isAnalyzing}
        />
      </div>

      <FixedInputArea
        userInput={userInput}
        setUserInput={setUserInput}
        onSubmit={handleSubmit}
        onQuickQuestion={handleQuickQuestion}
        onVoiceInput={handleVoiceInput}
        isDisabled={isDisabled}
        isThinking={speechSynthesis.isThinking}
        isSpeaking={speechSynthesis.isSpeaking}
      />

      <StatusPanel
        isAnalysisEnabled={isAnalysisEnabled}
        onToggleAnalysis={toggleAnalysis}
        pandaMemory={pandaLearning.pandaMemory}
        relationshipName={pandaLearning.getIntimacyDisplayLevel()}
        intimacyMessage={pandaLearning.getIntimacyDisplayMessage()}
        isAnimating={pandaLearning.intimacyAnimating}
        onShareCard={handleShareCard}
        isClientMounted={isClientMounted}
        getMilestoneTitle={getMilestoneTitle}
        analyserBridge={audioAnalysis.analyserBridge}
        latestAnalysisResult={audioAnalysis.latestAnalysisResult}
        isAnalyzing={audioAnalysis.isAnalyzing}
      />

      <footer className="bg-white/60 backdrop-blur-sm border-t border-white/30 p-4 text-center flex-shrink-0">
        <div className="max-w-2xl mx-auto">
          <div className="inline-flex items-center gap-2 bg-orange-100/80 text-orange-700 px-3 py-1.5 rounded-full text-xs mb-2">
            <span>â„¹ï¸</span>
            <span>ã“ã®ç¿»è¨³ã¯æ“¬ä¼¼çš„ãªæ¼”å‡ºã§ã™</span>
          </div>
          <p className="text-xs text-gray-600">
            åœ’å†…é™å®šã®&quot;ç‰¹åˆ¥ãƒœã‚¤ã‚¹&quot;ã‚‚æº–å‚™ä¸­ï¼
            <a
              href="https://www.city.sabae.fukui.jp/nishiyama_zoo/"
              target="_blank"
              rel="noopener noreferrer"
              className="font-medium text-orange-600 hover:text-orange-700 underline decoration-orange-300 hover:decoration-orange-500 transition-colors"
            >
              è¥¿å±±å‹•ç‰©åœ’ã§ä¼šã„ã«æ¥ã¦ã­ğŸ¾
            </a>
          </p>
        </div>
      </footer>

      {pandaLearning.showMilestone && (
        <MilestoneNotification
          newUnlocks={pandaLearning.newUnlocks}
          onClose={() => {
            pandaLearning.setShowMilestone(false)
            pandaLearning.setNewUnlocks([])
          }}
        />
      )}

      {pandaLearning.showShareCard && (
        <ShareCardGenerator
          cardData={{
            intimacyLevel: pandaLearning.pandaMemory.intimacyLevel,
            intimacyLevelName: pandaLearning.getIntimacyDisplayLevel(),
            totalConversations: pandaLearning.pandaMemory.totalConversations,
            uniqueDays: pandaLearning.pandaMemory.uniqueDays,
            consecutiveDays: pandaLearning.pandaMemory.consecutiveDays,
            specialUnlocks: pandaLearning.pandaMemory.specialUnlocks,
            relationshipMessage: pandaLearning.getIntimacyDisplayMessage(),
            timestamp: new Date()
          }}
          audioContext={speechSynthesis.audioContext}
          onClose={() => pandaLearning.setShowShareCard(false)}
        />
      )}
    </div>
  )
}
