/**
 * Speech Synthesis Custom Hook
 *
 * éŸ³å£°åˆæˆæ©Ÿèƒ½ã‚’æä¾›ã™ã‚‹ã‚«ã‚¹ã‚¿ãƒ ãƒ•ãƒƒã‚¯
 * - AudioContext ã®ç®¡ç†
 * - éŸ³å£°å†ç”Ÿå‡¦ç†
 * - ç™ºè©±çŠ¶æ…‹ç®¡ç†
 * - è¿”ç­”é¸æŠã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç”Ÿæˆ
 */

import { useState, useRef, useCallback } from 'react'
import { selectPandaReply, type PandaReply } from '@/data/replies'
import {
  speakLikePandaWithAnalysis,
  speakLikePanda,
  initializeAudioContext,
  createVariedSpeechParams,
  type SpeechAnalysisResult,
  type SpeechParams
} from '@/lib/pandaSpeech'
import type { AnalyserBridge } from '@/types/audio'

export interface SpeechRequest {
  input: string
  isUserInput: boolean
  adjustedParams: SpeechParams
  analyserBridge: AnalyserBridge | null
  isAnalysisEnabled: boolean
}

export interface SpeechResult {
  reply: PandaReply
  speechResult: SpeechAnalysisResult
}

export interface UseSpeechSynthesisConfig {
  enabled: boolean
}

export interface UseSpeechSynthesisReturn {
  // State
  audioContext: AudioContext | null
  isSpeaking: boolean
  isThinking: boolean
  currentReply: PandaReply | null

  // Actions
  initializeAudio: () => Promise<AudioContext | null>
  performSpeech: (request: SpeechRequest) => Promise<SpeechResult | null>
  setIsSpeaking: (value: boolean) => void
  setIsThinking: (value: boolean) => void
  setCurrentReply: (reply: PandaReply | null) => void
  getReplyForInput: (input: string) => PandaReply
  createSpeechParams: (replyId: number) => SpeechParams
}

export function useSpeechSynthesis(config: UseSpeechSynthesisConfig): UseSpeechSynthesisReturn {
  const { enabled } = config

  // State
  const [isSpeaking, setIsSpeaking] = useState(false)
  const [isThinking, setIsThinking] = useState(false)
  const [currentReply, setCurrentReply] = useState<PandaReply | null>(null)
  const audioContextRef = useRef<AudioContext | null>(null)

  // AudioContext ã‚’åˆæœŸåŒ–
  const initializeAudio = useCallback(async (): Promise<AudioContext | null> => {
    if (!enabled) {
      return null
    }

    if (audioContextRef.current) {
      return audioContextRef.current
    }

    try {
      console.log('ğŸ”Š Initializing AudioContext...')
      const context = await initializeAudioContext()
      audioContextRef.current = context
      console.log('âœ… AudioContext initialized successfully')
      return context
    } catch (error) {
      console.error('âŒ Failed to initialize AudioContext:', error)
      return null
    }
  }, [enabled])

  // å…¥åŠ›ã«å¯¾ã™ã‚‹è¿”ç­”ã‚’é¸æŠ
  const getReplyForInput = useCallback((input: string): PandaReply => {
    return selectPandaReply(input)
  }, [])

  // è¿”ç­”IDã‹ã‚‰æ„å›³ã‚’åˆ¤å®šã—ã¦ã‚¹ãƒ”ãƒ¼ãƒãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
  const createSpeechParams = useCallback((replyId: number): SpeechParams => {
    let intent: 'greeting' | 'hungry' | 'playful' | 'random' = 'random'
    if (replyId === 1) intent = 'hungry'
    else if (replyId === 2) intent = 'playful'
    else if (replyId === 3) intent = 'greeting'

    return createVariedSpeechParams(intent)
  }, [])

  // éŸ³å£°åˆæˆã‚’å®Ÿè¡Œ
  const performSpeech = useCallback(async (request: SpeechRequest): Promise<SpeechResult | null> => {
    if (!enabled) {
      return null
    }

    const { input, adjustedParams, analyserBridge, isAnalysisEnabled } = request

    console.log('ğŸµ Performing speech synthesis:', {
      input,
      hasAnalyserBridge: !!analyserBridge,
      isAnalysisEnabled
    })

    try {
      // AudioContext ã‚’ç¢ºä¿
      const context = await initializeAudio()
      if (!context) {
        throw new Error('AudioContext not available')
      }

      // è¿”ç­”ã‚’é¸æŠ
      const reply = getReplyForInput(input)

      // éŸ³å£°å†ç”Ÿ
      let speechResult: SpeechAnalysisResult

      if (isAnalysisEnabled && analyserBridge) {
        console.log('ğŸ¤ Using analysis-enabled speech synthesis')
        speechResult = await speakLikePandaWithAnalysis(
          context,
          reply.src,
          adjustedParams,
          analyserBridge
        )
      } else {
        console.log('ğŸ”Š Using traditional speech synthesis')
        const duration = await speakLikePanda(context, reply.src, adjustedParams)
        speechResult = {
          actualDuration: duration,
          grainTimeline: []
        }
      }

      console.log('âœ… Speech synthesis completed:', {
        duration: speechResult.actualDuration,
        grainCount: speechResult.grainTimeline.length
      })

      return { reply, speechResult }
    } catch (error) {
      console.error('âŒ Speech synthesis failed:', error)
      throw error
    }
  }, [enabled, initializeAudio, getReplyForInput])

  return {
    // State
    audioContext: audioContextRef.current,
    isSpeaking,
    isThinking,
    currentReply,

    // Actions
    initializeAudio,
    performSpeech,
    setIsSpeaking,
    setIsThinking,
    setCurrentReply,
    getReplyForInput,
    createSpeechParams
  }
}
